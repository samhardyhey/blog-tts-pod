{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# re-assign issue/article numbers, whoops\n",
    "df = (\n",
    "    pd.read_csv(\"./data/naut_all.csv\")\n",
    "    .assign(issue_number=lambda x: x.issue_title.factorize()[0] + 1)\n",
    "    .assign(article_number=lambda x: x.groupby(\"issue_number\").cumcount() + 1)\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP cost?\n",
    "def string_size_in_bytes(s):\n",
    "    return len(s.encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "# 23 million bytes\n",
    "(df.article.apply(string_size_in_bytes).sum() - 1000000) * 0.000016\n",
    "# ~353.800848 US for all text, less free month allowance\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coqui price estimates?\n",
    "from pathlib import Path\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 10 TTS\n",
    "audio_files = list(Path(\"./data/tts_output/tacotron2_ddc_ph\").rglob(\"*/*.mp3\"))\n",
    "\n",
    "\n",
    "def get_audio_length(filename):\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "    return len(audio)  # length in milliseconds\n",
    "\n",
    "\n",
    "audio_all = []\n",
    "for audio_file in audio_files:\n",
    "    length = get_audio_length(audio_file) / 1000.0  # convert to seconds\n",
    "    audio_all.append(length)\n",
    "\n",
    "# hours > https://coqui.ai/pricing > $20/4 hours\n",
    "sum(audio_all) / 60 / 60\n",
    "# 2.2028605555555556, yikes\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coqui model revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS(model_name=\"tts_models/en/vctk/vits\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = [\n",
    "    \"ED\\n\",\n",
    "    \"p225\",\n",
    "    \"p226\",\n",
    "    \"p227\",\n",
    "    \"p228\",\n",
    "    \"p229\",\n",
    "    \"p230\",\n",
    "    \"p231\",\n",
    "    \"p232\",\n",
    "    \"p233\",\n",
    "    \"p234\",\n",
    "    \"p236\",\n",
    "    \"p237\",\n",
    "    \"p238\",\n",
    "    \"p239\",\n",
    "    \"p240\",\n",
    "    \"p241\",\n",
    "    \"p243\",\n",
    "    \"p244\",\n",
    "    \"p245\",\n",
    "    \"p246\",\n",
    "    \"p247\",\n",
    "    \"p248\",\n",
    "    \"p249\",\n",
    "    \"p250\",\n",
    "    \"p251\",\n",
    "    \"p252\",\n",
    "    \"p253\",\n",
    "    \"p254\",\n",
    "    \"p255\",\n",
    "    \"p256\",\n",
    "    \"p257\",\n",
    "    \"p258\",\n",
    "    \"p259\",\n",
    "    \"p260\",\n",
    "    \"p261\",\n",
    "    \"p262\",\n",
    "    \"p263\",\n",
    "    \"p264\",\n",
    "    \"p265\",\n",
    "    \"p266\",\n",
    "    \"p267\",\n",
    "    \"p268\",\n",
    "    \"p269\",\n",
    "    \"p270\",\n",
    "    \"p271\",\n",
    "    \"p272\",\n",
    "    \"p273\",\n",
    "    \"p274\",\n",
    "    \"p275\",\n",
    "    \"p276\",\n",
    "    \"p277\",\n",
    "    \"p278\",\n",
    "    \"p279\",\n",
    "    \"p280\",\n",
    "    \"p281\",\n",
    "    \"p282\",\n",
    "    \"p283\",\n",
    "    \"p284\",\n",
    "    \"p285\",\n",
    "    \"p286\",\n",
    "    \"p287\",\n",
    "    \"p288\",\n",
    "    \"p292\",\n",
    "    \"p293\",\n",
    "    \"p294\",\n",
    "    \"p295\",\n",
    "    \"p297\",\n",
    "    \"p298\",\n",
    "    \"p299\",\n",
    "    \"p300\",\n",
    "    \"p301\",\n",
    "    \"p302\",\n",
    "    \"p303\",\n",
    "    \"p304\",\n",
    "    \"p305\",\n",
    "    \"p306\",\n",
    "    \"p307\",\n",
    "    \"p308\",\n",
    "    \"p310\",\n",
    "    \"p311\",\n",
    "    \"p312\",\n",
    "    \"p313\",\n",
    "    \"p314\",\n",
    "    \"p316\",\n",
    "    \"p317\",\n",
    "    \"p318\",\n",
    "    \"p323\",\n",
    "    \"p326\",\n",
    "    \"p329\",\n",
    "    \"p330\",\n",
    "    \"p333\",\n",
    "    \"p334\",\n",
    "    \"p335\",\n",
    "    \"p336\",\n",
    "    \"p339\",\n",
    "    \"p340\",\n",
    "    \"p341\",\n",
    "    \"p343\",\n",
    "    \"p345\",\n",
    "    \"p347\",\n",
    "    \"p351\",\n",
    "    \"p360\",\n",
    "    \"p361\",\n",
    "    \"p362\",\n",
    "    \"p363\",\n",
    "    \"p364\",\n",
    "    \"p374\",\n",
    "    \"p376\",\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tts import output_dir\n",
    "from utils import logger, nautilus_editors_note\n",
    "\n",
    "\n",
    "def tts_coqui_vctk(speaker_index, text, save_path):\n",
    "    tts = TTS(model_name=\"tts_models/en/vctk/vits\", gpu=True)\n",
    "    if save_path.parent.exists() is False:\n",
    "        save_path.parent.mkdir(parents=True)\n",
    "    # coqui_output_dir = output_dir / \"coqui\"\n",
    "    # if coqui_output_dir.exists() is False:\n",
    "    #     coqui_output_dir.mkdir(parents=True)\n",
    "    # save_file = coqui_output_dir / f\"{to_snake_case(Path(model_name).name)}_{text_name}.mp3\"\n",
    "    start = time.time()\n",
    "    tts.tts_to_file(text=text, file_path=save_path, speaker=speaker_index)\n",
    "    end = time.time()\n",
    "    logger.info(f\"Successuflly Coqui TTS {save_path.name} in {end - start} seconds\")\n",
    "\n",
    "\n",
    "for speaker in speakers[1:]:\n",
    "    speaker\n",
    "    # output_file = output_dir / f\"vctk_{speaker}_nautilus_editors_note.mp3\"\n",
    "    # tts_coqui_vctk(speaker, nautilus_editors_note, output_file)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tts --model_name \"tts_models/en/vctk/vits\" \\\n",
    "--list_speaker_idxs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"ED\\n\": 0,\n",
    "    \"p225\": 1,\n",
    "    \"p226\": 2,\n",
    "    \"p227\": 3,\n",
    "    \"p228\": 4,\n",
    "    \"p229\": 5,\n",
    "    \"p230\": 6,\n",
    "    \"p231\": 7,\n",
    "    \"p232\": 8,\n",
    "    \"p233\": 9,\n",
    "    \"p234\": 10,\n",
    "    \"p236\": 11,\n",
    "    \"p237\": 12,\n",
    "    \"p238\": 13,\n",
    "    \"p239\": 14,\n",
    "    \"p240\": 15,\n",
    "    \"p241\": 16,\n",
    "    \"p243\": 17,\n",
    "    \"p244\": 18,\n",
    "    \"p245\": 19,\n",
    "    \"p246\": 20,\n",
    "    \"p247\": 21,\n",
    "    \"p248\": 22,\n",
    "    \"p249\": 23,\n",
    "    \"p250\": 24,\n",
    "    \"p251\": 25,\n",
    "    \"p252\": 26,\n",
    "    \"p253\": 27,\n",
    "    \"p254\": 28,\n",
    "    \"p255\": 29,\n",
    "    \"p256\": 30,\n",
    "    \"p257\": 31,\n",
    "    \"p258\": 32,\n",
    "    \"p259\": 33,\n",
    "    \"p260\": 34,\n",
    "    \"p261\": 35,\n",
    "    \"p262\": 36,\n",
    "    \"p263\": 37,\n",
    "    \"p264\": 38,\n",
    "    \"p265\": 39,\n",
    "    \"p266\": 40,\n",
    "    \"p267\": 41,\n",
    "    \"p268\": 42,\n",
    "    \"p269\": 43,\n",
    "    \"p270\": 44,\n",
    "    \"p271\": 45,\n",
    "    \"p272\": 46,\n",
    "    \"p273\": 47,\n",
    "    \"p274\": 48,\n",
    "    \"p275\": 49,\n",
    "    \"p276\": 50,\n",
    "    \"p277\": 51,\n",
    "    \"p278\": 52,\n",
    "    \"p279\": 53,\n",
    "    \"p280\": 54,\n",
    "    \"p281\": 55,\n",
    "    \"p282\": 56,\n",
    "    \"p283\": 57,\n",
    "    \"p284\": 58,\n",
    "    \"p285\": 59,\n",
    "    \"p286\": 60,\n",
    "    \"p287\": 61,\n",
    "    \"p288\": 62,\n",
    "    \"p292\": 63,\n",
    "    \"p293\": 64,\n",
    "    \"p294\": 65,\n",
    "    \"p295\": 66,\n",
    "    \"p297\": 67,\n",
    "    \"p298\": 68,\n",
    "    \"p299\": 69,\n",
    "    \"p300\": 70,\n",
    "    \"p301\": 71,\n",
    "    \"p302\": 72,\n",
    "    \"p303\": 73,\n",
    "    \"p304\": 74,\n",
    "    \"p305\": 75,\n",
    "    \"p306\": 76,\n",
    "    \"p307\": 77,\n",
    "    \"p308\": 78,\n",
    "    \"p310\": 79,\n",
    "    \"p311\": 80,\n",
    "    \"p312\": 81,\n",
    "    \"p313\": 82,\n",
    "    \"p314\": 83,\n",
    "    \"p316\": 84,\n",
    "    \"p317\": 85,\n",
    "    \"p318\": 86,\n",
    "    \"p323\": 87,\n",
    "    \"p326\": 88,\n",
    "    \"p329\": 89,\n",
    "    \"p330\": 90,\n",
    "    \"p333\": 91,\n",
    "    \"p334\": 92,\n",
    "    \"p335\": 93,\n",
    "    \"p336\": 94,\n",
    "    \"p339\": 95,\n",
    "    \"p340\": 96,\n",
    "    \"p341\": 97,\n",
    "    \"p343\": 98,\n",
    "    \"p345\": 99,\n",
    "    \"p347\": 100,\n",
    "    \"p351\": 101,\n",
    "    \"p360\": 102,\n",
    "    \"p361\": 103,\n",
    "    \"p362\": 104,\n",
    "    \"p363\": 105,\n",
    "    \"p364\": 106,\n",
    "    \"p374\": 107,\n",
    "    \"p376\": 108,\n",
    "}\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import nautilus_editors_note\n",
    "\n",
    "nautilus_editors_note\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code equivlanet for these models?\n",
    "!tts --text \"Behold the humble nautilus. Just about a foot in diameter, it is a slow bottom-dweller with short tentacles that moves through the water with an unsteady wobble. It\\'s also 500 million years old and, in its day, was the best and brightest, using its newly evolved depth control to lay waste to acre after acre of scuttling crustacean prey.\\nWe became interested in it here at Nautilus because, well, we stole its name. But also because (for a mollusk) it represents a remarkable intersection of science, math, myth, and culture. Since that is exactly the kind of intersection we love to write about, we decided to put together a little \"teaser\" issue all about it.\\nThere\\'s the science. The nautilus has a beautiful, logarithmic, and fractal spiral in its shell. Benoit Mandelbrot, discoverer of the fractal, gives us a few words on that topic. One of the world\\'s foremost nautilus experts, Peter Ward, tells us about nautilus evolution and biology, and about his life of nautilus research.\\nThen, the myth: from Jules Verne\\'s fictional submarine, to Oliver Wendell Holmes\\' poem, to how and why we turn science into story.\\nTwo chapters, one undersea creature. Welcome aboard.\\nMichael Segal\\n    Editor in Chief\"\\\n",
    "--out_path spkr-out.wav --model_name \"tts_models/en/vctk/vits\" \\\n",
    "--use_cuda True \\\n",
    "--speaker_idx \"p227\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tortoise Diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from tortoise.api import MODELS_DIR, TextToSpeech\n",
    "from tortoise.utils.audio import load_voices\n",
    "\n",
    "sys.path.append(\"../tortoise-tts/tortoise\")\n",
    "\n",
    "\n",
    "voices = \"\"\"angie                daniel  freeman  jlaw  myself  rainbow       tom           train_dotrice  train_grace     train_mouse\n",
    "applejack            deniro  geralt   lj    pat     snakes        train_atkins  train_dreams   train_kennard   weaver\n",
    "cond_latent_example  emma    halle    mol   pat2    tim_reynolds  train_daws    train_empire   train_lescault  william\"\"\"\n",
    "\n",
    "\n",
    "output_dir = Path(\"./data/tts_output/dev/tortoise\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "voices_formatted = [word for line in voices.splitlines() for word in line.split()]\n",
    "model = voices_formatted[0]\n",
    "\n",
    "tts = TextToSpeech(models_dir=MODELS_DIR)\n",
    "voice_samples, conditioning_latents = load_voices([model])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from utils import nautilus_editors_note\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "sents = [e.text for e in list(nlp(nautilus_editors_note).sents)]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(sents):\n",
    "    print(sent)\n",
    "    gen, dbg_state = tts.tts_with_preset(\n",
    "        sent,\n",
    "        k=1,\n",
    "        voice_samples=voice_samples,\n",
    "        conditioning_latents=conditioning_latents,\n",
    "        preset=\"fast\",\n",
    "        use_deterministic_seed=42,\n",
    "        return_deterministic_state=True,\n",
    "        cvvp_amount=0.0,\n",
    "    )\n",
    "    torchaudio.save(str(output_dir / f\"test_{idx}.wav\"), gen.squeeze(0).cpu(), 24000)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picks?\n",
    "ddc\n",
    "\n",
    "en_au_neural2_a\n",
    "en_au_neural2_b\n",
    "\n",
    "en_au_neural2_c\n",
    "en_au_neural2_d\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configurations = [\n",
    "    {\n",
    "        \"type\": \"coqui\",\n",
    "        \"name\": \"tts_models/en/ljspeech/tacotron2-DDC\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"coqui\",\n",
    "        \"name\": \"tts_models/en/ljspeech/tacotron2-DDC\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"coqui\",\n",
    "        \"name\": \"tts_models/en/ljspeech/tacotron2-DDC\",\n",
    "    },\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tts import tts_coqui\n",
    "from utils import to_snake_case\n",
    "\n",
    "coqui_model = \"tts_models/en/ljspeech/tacotron2-DDC_ph\"\n",
    "output_dir = Path(\"./data/tts_output/\") / to_snake_case(Path(coqui_model).name)\n",
    "if output_dir.exists() is False:\n",
    "    output_dir.mkdir(parents=True)\n",
    "\n",
    "for idx, row in df.head(10).iterrows():\n",
    "    issue_dir = output_dir / f\"{row.issue_number}_{to_snake_case(row.issue_title)}\"\n",
    "    if issue_dir.exists() is False:\n",
    "        issue_dir.mkdir(parents=True)\n",
    "    article_fp = issue_dir / f\"{row.article_number}_{to_snake_case(row.headline)}.mp3\"\n",
    "\n",
    "    tts_coqui(coqui_model, row.article, article_fp)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_dir / f\"{to_snake_case(row.headline)}.mp3\"\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fb7ad1863bba2e2a149175e2f293cc7effc6691cc580cfc80ad00772d007246"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
